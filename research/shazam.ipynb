{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "audio, sr = librosa.load(librosa.example('nutcracker'))\n",
    "audio_2, sr = librosa.load(librosa.example('brahms'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMITS = np.array([40, 80, 120, 180, 300, np.inf])\n",
    "\n",
    "\n",
    "def get_peak_frequencies(y, sr=22_050, n_fft=2_048):\n",
    "    S = np.abs(librosa.stft(y, n_fft=n_fft))\n",
    "\n",
    "    all_frames = np.arange(S.shape[1])\n",
    "\n",
    "    frequencies = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "    times = librosa.frames_to_time(all_frames)\n",
    "\n",
    "    bands = np.array([np.argmax(LIMITS >= freq) for freq in frequencies])\n",
    "\n",
    "    S_out = np.zeros_like(S, dtype=np.bool8)\n",
    "\n",
    "    for band in np.unique(bands):\n",
    "        start_row = np.argmax(bands == band)\n",
    "        end_row = len(bands) - np.argmax(bands[::-1] == band)\n",
    "\n",
    "        slice = S[start_row:end_row]\n",
    "\n",
    "        # TODO: consider using moving window average instead\n",
    "        # TODO: compute the mean only for single frame instead of song for comparison\n",
    "\n",
    "        # Computing threshold by picking loudest freq in freq slice\n",
    "        # and averaging their amplitudes (multiplied by a constant)\n",
    "        amplitude_threshold = np.mean(np.max(slice, axis=0)) * 2\n",
    "\n",
    "        # Max frequency bin index of a slice for each FFT frame\n",
    "        # Not filtered by mean yet\n",
    "        max_freq_bin = start_row + np.argmax(slice, axis=0)\n",
    "\n",
    "        # Pick only frequencies, if their amplitude is higher than\n",
    "        # the mean amplitude of the entire band captured from the whole song\n",
    "        mask = S[max_freq_bin, all_frames] >= amplitude_threshold\n",
    "        S_out[max_freq_bin[mask], all_frames[mask]] = True\n",
    "\n",
    "    result = np.apply_along_axis(\n",
    "        lambda key: np.array(\n",
    "            [np.floor(frequencies[key[0]]), times[key[1]]]\n",
    "        ),\n",
    "        1,\n",
    "        np.argwhere(S_out > 0)\n",
    "    )\n",
    "\n",
    "    result = result[result[:, 0].argsort()]\n",
    "    result = result[result[:, 1].argsort(kind=\"mergesort\")]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_hashes_from_peaks(peaks, window_size=5):\n",
    "    flat = np.apply_along_axis(\n",
    "        lambda key: {\"freq\": key[0], \"time\": key[1]}, 1, peaks)\n",
    "\n",
    "    hashes = []\n",
    "    for window in np.lib.stride_tricks.sliding_window_view(flat, window_size):\n",
    "        time = window[0][\"time\"]\n",
    "        hash = \",\".join([str(int(item[\"freq\"])) for item in window])\n",
    "\n",
    "        hashes.append({\"time\": time, \"hash\": hash})\n",
    "\n",
    "    return hashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out matches\n",
    "# 1) Create a fingerprint from recording\n",
    "# 2) Find the intersection of 2 fingerprints based on their hashes\n",
    "# 3) Gather all deltas (distance between needle and search), count how many deltas are matching => sort by number of matching deltas\n",
    "\n",
    "\n",
    "def compare_fingerprints(music_hashes, record_hashes):\n",
    "    # Construct dict from music hashes\n",
    "    db = defaultdict(list)\n",
    "\n",
    "    for music in music_hashes:\n",
    "        db[music[\"hash\"]].append(music[\"time\"])\n",
    "\n",
    "    durations = defaultdict(int)\n",
    "    for record in record_hashes:\n",
    "        for music_time in db[record[\"hash\"]]:\n",
    "            delta = abs(music_time - record[\"time\"])\n",
    "            durations[str(delta)] += 1\n",
    "\n",
    "    return sorted(durations.values())[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = get_hashes_from_peaks(get_peak_frequencies(audio))\n",
    "f2 = get_hashes_from_peaks(get_peak_frequencies(\n",
    "    audio[int(audio.shape[-1] / 4): int(3 * audio.shape[-1] / 4)]))\n",
    "compare_fingerprints(f1, f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
